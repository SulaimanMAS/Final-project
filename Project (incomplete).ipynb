{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46574152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense ,Dropout\n",
    "import glob\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow_io as tfio\n",
    "from scipy.io import wavfile as wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label all of the audio files in train1 directory except the (ALL , test) folder\n",
    "\n",
    "files = glob.glob('train1/*/*')\n",
    "files1 = glob.glob('train1/*\\\\')\n",
    "print(files)\n",
    "l2 = []\n",
    "for i, f in enumerate (files1):\n",
    "    \n",
    "    if f.find('All') > -1 or f.find('test') > -1:\n",
    "        continue;\n",
    "        \n",
    "    print(f)\n",
    "    l2.append(f)\n",
    "print(files1[0].replace('\\\\' ,  '/'))\n",
    "print(l2)\n",
    "l2\n",
    "df = pd.DataFrame()\n",
    "l =[]\n",
    "l3 = []\n",
    "for i, f in enumerate (files):\n",
    "    if f.find('All') > -1 or f.find('test') > -1:\n",
    "            continue\n",
    "    n=f\n",
    "    for x in l2:\n",
    "        n = n.replace(x , '')\n",
    "        \n",
    "    shaikh = f.replace('train1' , '')\n",
    "    shaikh = shaikh.replace(n , '')\n",
    "    shaikh = shaikh.replace('\\\\' , '')\n",
    "    print(n)\n",
    "    print(shaikh)\n",
    "    l.append(n)\n",
    "    l3.append(shaikh)\n",
    "\n",
    "df['fileName'] = l\n",
    "df['shaikh'] = l3\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shaikh'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5423292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd688d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from an audio file\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=50)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445104fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Now we iterate through every audio file and extract features \n",
    "# using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(df.iterrows()):\n",
    "    # We will put a copy of all of the audio files in a folder called (All) to reach it easily and use our dataframe to lable it\n",
    "    file_name = 'train1/All/'+str(row['fileName'])\n",
    "    final_class_labels=row[\"shaikh\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df\n",
    "#audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35532858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###for RNN\n",
    "X2 = np.expand_dims(X, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76124123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f38638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94777fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac76deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590446f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lb = LabelEncoder()\n",
    "#y = lb.fit_transform(y)\n",
    "y=np.array(pd.get_dummies(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[311])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b92eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train,X2_test,y_train,y_test=train_test_split(X2,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ed3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = MinMaxScaler(feature_range=(-1 , 1))\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fe2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb703bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1446a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79476a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e18264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,LSTM,GRU,SimpleRNN,Embedding ,Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d6634",
   "metadata": {},
   "outputs": [],
   "source": [
    "###ANN\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(50,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab087b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 50*3\n",
    "\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1 )\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"testsudais3.wav\"\n",
    "prediction_feature=features_extractor(filename)\n",
    "prediction_feature=prediction_feature.reshape(1,-1)\n",
    "model.predict(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "###RNN\n",
    "model2=Sequential()\n",
    "\n",
    "\n",
    "###first layer\n",
    "model2.add(LSTM(100, input_shape=(X2.shape[1:]) , return_sequences=True))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.65))\n",
    "###second layer\n",
    "model2.add(LSTM(200 ,  return_sequences=True))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.65))\n",
    "\n",
    "###third layer\n",
    "model2.add(LSTM(100 ,  return_sequences=True))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.65))\n",
    "\n",
    "model2.add(LSTM(50 ,  return_sequences=False))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.65))\n",
    "\n",
    "###final layer\n",
    "model2.add(Dense(num_labels))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2900f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer2 = ModelCheckpoint(filepath='saved_models/audio_classification2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start2 = datetime.now()\n",
    "\n",
    "model2.fit(X2_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X2_test, y_test), callbacks=[checkpointer2], verbose=1 )\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"testsaad3.wav\"\n",
    "prediction_feature=features_extractor(filename)\n",
    "prediction_feature=prediction_feature.reshape(1 , 1 , 50)\n",
    "model2.predict(prediction_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f42180",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_feature.shape = (1, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f0f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
